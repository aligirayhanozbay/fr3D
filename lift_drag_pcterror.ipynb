{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "78ffe1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import h5py\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.path as mplPath\n",
    "from evtk import hl\n",
    "#from mayavi import mlab\n",
    "#mlab.init_notebook('itk')\n",
    "\n",
    "from fr3D.train.utils import setup_datasets\n",
    "from fr3D.data.utils import get_normalization\n",
    "from fr3D.models import ConvAutoencoder, ConvAutoencoderCGAN, ConvAutoencoderC\n",
    "\n",
    "def mape_with_threshold(yp, yt, pcterror_threshold=np.inf, max_magnitude_threshold=0.0, eps=1e-7):\n",
    "    pct_errors = 100*tf.abs((yp-yt)/(eps + yt))\n",
    "    pcterror_mask = pct_errors < pcterror_threshold\n",
    "    max_magnitude_mask = tf.logical_not(tf.abs(yt) < (max_magnitude_threshold*tf.reduce_max(tf.abs(yt))))\n",
    "    filtering_indices = tf.where(tf.logical_and(pcterror_mask, max_magnitude_mask))\n",
    "    filtered_pcterrors = tf.gather_nd(pct_errors, filtering_indices)\n",
    "    return float(tf.reduce_mean(filtered_pcterrors))\n",
    "\n",
    "def get_normalization_type(node_configs):\n",
    "    normalization_spec = {'method': None}\n",
    "    for node in node_configs:\n",
    "        if node['nodetype'] == 'normalize':\n",
    "            normalization_spec = node['normalization_spec']\n",
    "            break\n",
    "    normalizer = get_normalization(**normalization_spec, batch_mode=True)\n",
    "    return normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b72df71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training geometries: ('shape_69', 'shape_33', 'shape_37', 'shape_374', 'shape_239', 'shape_224', 'shape_160', 'shape_237', 'shape_135', 'cylinder', 'shape_152', 'shape_186', 'shape_92', 'shape_21', 'shape_58', 'shape_110', 'shape_88', 'shape_59', 'shape_14', 'shape_197', 'shape_55', 'shape_8', 'shape_170', 'shape_234', 'shape_43', 'shape_149', 'shape_228', 'shape_48', 'shape_130', 'shape_90', 'shape_137', 'shape_84', 'shape_361', 'shape_182', 'shape_68', 'shape_113', 'shape_244', 'shape_327', 'shape_216', 'shape_15', 'shape_63', 'shape_213', 'shape_126', 'shape_236', 'shape_50', 'shape_18', 'shape_157', 'shape_89', 'shape_17', 'shape_355', 'shape_29', 'shape_146', 'shape_164', 'shape_11', 'shape_150', 'shape_220', 'shape_13', 'shape_60', 'shape_12', 'shape_369', 'shape_218', 'shape_78', 'shape_331', 'shape_97', 'shape_329', 'shape_31', 'shape_39', 'shape_241', 'shape_41', 'shape_346', 'shape_94', 'shape_61', 'shape_23', 'shape_339', 'shape_255', 'shape_83', 'shape_338', 'shape_54', 'shape_206', 'shape_9')\n",
      "Test geometries: ('shape_34', 'shape_358', 'shape_74', 'shape_22', 'shape_183', 'shape_102', 'shape_326', 'shape_16', 'shape_107', 'shape_163', 'shape_76', 'shape_95', 'shape_52', 'shape_75', 'shape_67', 'shape_159', 'shape_343', 'shape_46', 'shape_147', 'shape_86', 'shape_325')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-16 14:14:56.882266: W tensorflow_io/core/kernels/audio_video_mp3_kernels.cc:271] libmp3lame.so.0 or lame functions are not available\n",
      "2022-12-16 14:14:56.882435: I tensorflow_io/core/kernels/cpu_check.cc:128] Your CPU supports instructions that this TensorFlow IO binary was not compiled to use: AVX2 FMA\n",
      "2022-12-16 14:14:57.196146: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-16 14:14:58.083142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38278 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:01:00.0, compute capability: 8.0\n",
      "2022-12-16 14:14:58.084654: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 38278 MB memory:  -> device: 1, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:43:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training geometries: ('shape_69', 'shape_33', 'shape_37', 'shape_374', 'shape_239', 'shape_224', 'shape_160', 'shape_237', 'shape_135', 'cylinder', 'shape_152', 'shape_186', 'shape_92', 'shape_21', 'shape_58', 'shape_110', 'shape_88', 'shape_59', 'shape_14', 'shape_197', 'shape_55', 'shape_8', 'shape_170', 'shape_234', 'shape_43', 'shape_149', 'shape_228', 'shape_48', 'shape_130', 'shape_90', 'shape_137', 'shape_84', 'shape_361', 'shape_182', 'shape_68', 'shape_113', 'shape_244', 'shape_327', 'shape_216', 'shape_15', 'shape_63', 'shape_213', 'shape_126', 'shape_236', 'shape_50', 'shape_18', 'shape_157', 'shape_89', 'shape_17', 'shape_355', 'shape_29', 'shape_146', 'shape_164', 'shape_11', 'shape_150', 'shape_220', 'shape_13', 'shape_60', 'shape_12', 'shape_369', 'shape_218', 'shape_78', 'shape_331', 'shape_97', 'shape_329', 'shape_31', 'shape_39', 'shape_241', 'shape_41', 'shape_346', 'shape_94', 'shape_61', 'shape_23', 'shape_339', 'shape_255', 'shape_83', 'shape_338', 'shape_54', 'shape_206', 'shape_9')\n",
      "Test geometries: ('shape_34', 'shape_358', 'shape_74', 'shape_22', 'shape_183', 'shape_102', 'shape_326', 'shape_16', 'shape_107', 'shape_163', 'shape_76', 'shape_95', 'shape_52', 'shape_75', 'shape_67', 'shape_159', 'shape_343', 'shape_46', 'shape_147', 'shape_86', 'shape_325')\n",
      "Training geometries: ('shape_69', 'shape_33', 'shape_37', 'shape_374', 'shape_239', 'shape_224', 'shape_160', 'shape_237', 'shape_135', 'cylinder', 'shape_152', 'shape_186', 'shape_92', 'shape_21', 'shape_58', 'shape_110', 'shape_88', 'shape_59', 'shape_14', 'shape_197', 'shape_55', 'shape_8', 'shape_170', 'shape_234', 'shape_43', 'shape_149', 'shape_228', 'shape_48', 'shape_130', 'shape_90', 'shape_137', 'shape_84', 'shape_361', 'shape_182', 'shape_68', 'shape_113', 'shape_244', 'shape_327', 'shape_216', 'shape_15', 'shape_63', 'shape_213', 'shape_126', 'shape_236', 'shape_50', 'shape_18', 'shape_157', 'shape_89', 'shape_17', 'shape_355', 'shape_29', 'shape_146', 'shape_164', 'shape_11', 'shape_150', 'shape_220', 'shape_13', 'shape_60', 'shape_12', 'shape_369', 'shape_218', 'shape_78', 'shape_331', 'shape_97', 'shape_329', 'shape_31', 'shape_39', 'shape_241', 'shape_41', 'shape_346', 'shape_94', 'shape_61', 'shape_23', 'shape_339', 'shape_255', 'shape_83', 'shape_338', 'shape_54', 'shape_206', 'shape_9')\n",
      "Test geometries: ('shape_34', 'shape_358', 'shape_74', 'shape_22', 'shape_183', 'shape_102', 'shape_326', 'shape_16', 'shape_107', 'shape_163', 'shape_76', 'shape_95', 'shape_52', 'shape_75', 'shape_67', 'shape_159', 'shape_343', 'shape_46', 'shape_147', 'shape_86', 'shape_325')\n",
      "Training geometries: ('shape_69', 'shape_33', 'shape_37', 'shape_374', 'shape_239', 'shape_224', 'shape_160', 'shape_237', 'shape_135', 'cylinder', 'shape_152', 'shape_186', 'shape_92', 'shape_21', 'shape_58', 'shape_110', 'shape_88', 'shape_59', 'shape_14', 'shape_197', 'shape_55', 'shape_8', 'shape_170', 'shape_234', 'shape_43', 'shape_149', 'shape_228', 'shape_48', 'shape_130', 'shape_90', 'shape_137', 'shape_84', 'shape_361', 'shape_182', 'shape_68', 'shape_113', 'shape_244', 'shape_327', 'shape_216', 'shape_15', 'shape_63', 'shape_213', 'shape_126', 'shape_236', 'shape_50', 'shape_18', 'shape_157', 'shape_89', 'shape_17', 'shape_355', 'shape_29', 'shape_146', 'shape_164', 'shape_11', 'shape_150', 'shape_220', 'shape_13', 'shape_60', 'shape_12', 'shape_369', 'shape_218', 'shape_78', 'shape_331', 'shape_97', 'shape_329', 'shape_31', 'shape_39', 'shape_241', 'shape_41', 'shape_346', 'shape_94', 'shape_61', 'shape_23', 'shape_339', 'shape_255', 'shape_83', 'shape_338', 'shape_54', 'shape_206', 'shape_9')\n",
      "Test geometries: ('shape_34', 'shape_358', 'shape_74', 'shape_22', 'shape_183', 'shape_102', 'shape_326', 'shape_16', 'shape_107', 'shape_163', 'shape_76', 'shape_95', 'shape_52', 'shape_75', 'shape_67', 'shape_159', 'shape_343', 'shape_46', 'shape_147', 'shape_86', 'shape_325')\n"
     ]
    }
   ],
   "source": [
    "Re = 500\n",
    "expt_variables = ['Pressure', 'U', 'V', 'W']\n",
    "\n",
    "dataset_path = f'/fr3D/postprocessed/annulus_64.h5'\n",
    "\n",
    "#ConvAutoencoderC\n",
    "experiment_configs = {expt_variable:f'/fr3D/configs/training/ConvAutoencoderC_{expt_variable}.json' for expt_variable in expt_variables}\n",
    "weights_paths = {expt_variable:f'/storage/weights{Re}/ConvAutoencoderC_{expt_variable}_Annulus64/ConvAutoencoderC_{expt_variable}_Annulus64.h5' for expt_variable in expt_variables}\n",
    "\n",
    "\n",
    "\n",
    "datasetf = h5py.File(dataset_path,'r')\n",
    "\n",
    "shuf_buf = 1\n",
    "\n",
    "train_datasets = {}\n",
    "test_datasets = {}\n",
    "sensor_shapes = {}\n",
    "full_field_shapes = {}\n",
    "normalizers = {}\n",
    "\n",
    "for expt_variable in experiment_configs:\n",
    "    config = json.load(open(experiment_configs[expt_variable],'r'))\n",
    "    train_datasets[expt_variable], test_datasets[expt_variable] = setup_datasets(config, dataset_path, shuf_buf, case_names=True, evaluation=True)\n",
    "    sensor_shapes[expt_variable] = train_datasets[expt_variable].element_spec[0][0].shape\n",
    "    full_field_shapes[expt_variable] = train_datasets[expt_variable].element_spec[0][1].shape\n",
    "    normalizers[expt_variable] = get_normalization_type(config['dataset']['node_configurations'])\n",
    "    \n",
    "dataset_iterators = {v: iter(test_datasets[v]) for v in test_datasets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "48ab5246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 45.02644 -18.40995   0.     ], shape=(3,), dtype=float32)\n",
      "tf.Tensor([9.0921955  0.21526259 0.        ], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def circular_pad(x, coords=True):\n",
    "    if coords:\n",
    "        r = np.zeros((x.shape[0]+2, x.shape[1]+2, x.shape[2]))\n",
    "    else:\n",
    "        r = np.zeros((x.shape[0]+2, x.shape[1]+2))\n",
    "    r[1:-1,1:-1] = x\n",
    "    \n",
    "    r[0,1:-1] = x[-1]\n",
    "    r[-1,1:-1] = x[0]\n",
    "    \n",
    "    if coords:\n",
    "        r[:,0,:2] = r[:,1,:2]\n",
    "        r[:,0,2] = x[0,0,2] - x[0,1,2]\n",
    "        \n",
    "        r[:,-1,:2] = r[:,-2,:2]\n",
    "        r[:,-1,2] = 2*x[0,-1,2] - x[0,-2,2]\n",
    "    return r\n",
    "\n",
    "def compute_surface_normals(ds):\n",
    "    r = {}\n",
    "    for shape in ds:\n",
    "        padded_coords = circular_pad(ds[shape]['full_field_coords'][0,...])\n",
    "        surface_coords = padded_coords\n",
    "        theta_direction_vector = (surface_coords[2:] - surface_coords[:-2])[:,1:-1]\n",
    "        z_direction_vector = (surface_coords[:,2:] - surface_coords[:,:-2])[1:-1]\n",
    "        \n",
    "        normal_vectors = np.cross(theta_direction_vector, z_direction_vector)\n",
    "        surface_normals = normal_vectors/np.linalg.norm(normal_vectors,axis=-1,keepdims=True)\n",
    "        r[shape] = tf.convert_to_tensor(surface_normals)\n",
    "    return r\n",
    "\n",
    "def compute_surface_normals2(ds, normalize=True):\n",
    "    r = {}\n",
    "    for shape in ds:\n",
    "        deltas = ds[shape]['full_field_coords'][1] - ds[shape]['full_field_coords'][0]\n",
    "        if normalize:\n",
    "            normals = deltas / np.linalg.norm(deltas,axis=-1,keepdims=True)\n",
    "        else:\n",
    "            normals = deltas\n",
    "        r[shape] = tf.convert_to_tensor(normals)\n",
    "    return r\n",
    "\n",
    "@tf.function\n",
    "def surface_integrate(vertex_values, vertex_coords):\n",
    "    \n",
    "    padded_coords = tf.concat([vertex_coords, vertex_coords[:1]],0)\n",
    "    padded_values = tf.concat([vertex_values, vertex_values[:1]],0)\n",
    "    \n",
    "    cell_mean_values = tf.nn.conv2d(\n",
    "        tf.convert_to_tensor([[padded_values]]),\n",
    "        tf.constant([[[[0.25]],[[0.25]]],[[[0.25]],[[0.25]]]]),\n",
    "        1, \"VALID\", data_format=\"NCHW\"\n",
    "    )[0,0]\n",
    "    \n",
    "    z_direction_vector = padded_coords[:-1, 1:] - padded_coords[:-1, :-1]\n",
    "    theta_direction_vector = -(padded_coords[1:,:-1] - padded_coords[:-1,:-1])\n",
    "    cell_normals = tf.linalg.cross(theta_direction_vector, z_direction_vector)\n",
    "    cell_areas = tf.linalg.norm(cell_normals, axis=-1)\n",
    "    \n",
    "    return tf.einsum('tzn,tz->n', cell_normals, cell_mean_values)#/(0.5*1.0*(1.0**2)*tf.reduce_sum(cell_areas))\n",
    "\n",
    "@tf.function\n",
    "def compute_shear_stresses(velocities, surface_normals, nu=1.0):\n",
    "    #get surface tangent component of velocity    \n",
    "    R = tf.constant([[0,-1,0],[1,0,0],[0,0,1]],dtype=velocities.dtype)\n",
    "    surface_normals_norm = tf.linalg.norm(surface_normals, axis=-1, keepdims=True)\n",
    "    surface_unit_tangents = tf.einsum('ij,tzj->tzi', R, surface_normals/surface_normals_norm)\n",
    "    velocity_tangent_component = tf.einsum('tzi,tzi->tz', surface_unit_tangents, velocities[1])\n",
    "    \n",
    "    #compute shear stresses from du/dn\n",
    "    tau = nu*velocity_tangent_component/(2*surface_normals_norm[...,0]**2.0)\n",
    "    return tau\n",
    "\n",
    "@tf.function\n",
    "def compute_friction_forces(shear_stresses, vertex_coords):\n",
    "    Fnormal = surface_integrate(shear_stresses, vertex_coords)\n",
    "    return tf.convert_to_tensor([Fnormal[1], -Fnormal[0], Fnormal[2]])\n",
    "\n",
    "pressure_forces = surface_integrate(\n",
    "    datasetf['cylinder']['full_field'][600,0,...,0],\n",
    "    datasetf['cylinder']['full_field_coords'][0,...]\n",
    ")\n",
    "\n",
    "\n",
    "print(pressure_forces)\n",
    "surface_normals_map = compute_surface_normals2(datasetf, normalize=False)\n",
    "tau = compute_shear_stresses(\n",
    "    datasetf['cylinder']['full_field'][600,...,1:],\n",
    "    surface_normals_map['cylinder'],\n",
    "    0.01\n",
    ")\n",
    "friction_forces = compute_friction_forces(tau, datasetf['cylinder']['full_field_coords'][0,...])\n",
    "print(friction_forces)\n",
    "#surface_normals_map = compute_surface_normals(datasetf)\n",
    "\n",
    "#print(surface_normals_map2['cylinder'][:,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc058b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "\n",
    "for v in expt_variables:\n",
    "    config = json.load(open(experiment_configs[v],'r'))\n",
    "    model = ConvAutoencoderC(dense_input_units=sensor_shapes[v][1],\n",
    "                             autoencoder_input_shape=full_field_shapes[v][1:],\n",
    "                             **config['model'])\n",
    "    loss_fn = \"mse\"#tf.keras.losses.get(config['training']['loss'])\n",
    "    model.compile(l_optimizer= tf.keras.optimizers.get(config['training']['l_optimizer']),\n",
    "                  loss=loss_fn,\n",
    "                  optimizer = tf.keras.optimizers.get(config['training']['ae_optimizer']),\n",
    "                  metrics = config['training'].get('metrics', None))\n",
    "    model.load_weights(weights_paths[v])\n",
    "    models[v] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "acce48c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 3, 4, 4])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
